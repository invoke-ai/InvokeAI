---
title: Others
---

## **Google Colab**

Stable Diffusion AI Notebook: <a
href="https://colab.research.google.com/github/lstein/stable-diffusion/blob/main/notebooks/Stable_Diffusion_AI_Notebook.ipynb"
target="_parent"> <img
src="https://colab.research.google.com/assets/colab-badge.svg"
alt="Open In Colab"/></a> <br> Open and follow instructions to use an isolated environment running
Dream.<br>

Output Example: ![Colab Notebook](../assets/colab_notebook.png)

---

## **Seamless Tiling**

The seamless tiling mode causes generated images to seamlessly tile with itself. To use it, add the
`--seamless` option when starting the script which will result in all generated images to tile, or
for each `dream>` prompt as shown here:

```python
dream> "pond garden with lotus by claude monet" --seamless -s100 -n4
```

---

## **Show Progress**

Provides a visual preview of the image generation process.

`-show_progress <step_count: int> <duration: float>`

- `step_count`: The number of steps between each progress update. Default: `5`.

- `duration`: The duration (in seconds) for how long you want the final image to be displayed before
  the preview closes automatically. Default: `2`.

- Set step_count to the same value as your steps to get a preview only when the image is fully
  generated.

- Enter duration: `0` to keep it open forever until user presses a key. Note that this will block
  the code from running further until user input.

If you have post processing options, the preview will close after image generation and reopen again
with the updated changes.

---

## **Save Progress & Make Video**

Allows you to save the intermediate steps during the image generation process and make a video out
of it.

`-save_progress <step_count: int default=5> <video_options: v | vo default: None>`

- `step_count`: The number of steps between each intermediate image saved. When no value is given,
  it defaults to `5`.
- `video_options`: Allows you to generate a video from the intermediate images. Takes two options:
  `v` (Video) or `vo` (Video Only)

### **Usage**

`-save_progress`: Saves intermediate frames every 5 steps. No video generation.

`-save_progress 3`: Saves intermediate frames every 3 steps. No video generation.

`-save_progress 3 v`: Saves intermediate frames every 3 steps. Also generates a video from the
frames at the end.

`-save_progress 3 vo`: Does not save intermediate frames but generates a video of the process every
3 steps.

`-show_progress 3 -save_progress 3 vo`: Shows a preview of the generation process updating every 3
seconds while also saving a video of the same.

---

## **Shortcuts: Reusing Seeds**

Since it is so common to reuse seeds while refining a prompt, there is now a shortcut as of version
1.11. Provide a `**-S**` (or `**--seed**`) switch of `-1` to use the seed of the most recent image
generated. If you produced multiple images with the `**-n**` switch, then you can go back further
using -2, -3, etc. up to the first image generated by the previous command. Sorry, but you can't go
back further than one command.

Here's an example of using this to do a quick refinement. It also illustrates using the new `**-G**`
switch to turn on upscaling and face enhancement (see previous section):

```bash
dream> a cute child playing hopscotch -G0.5
[...]
outputs/img-samples/000039.3498014304.png: "a cute child playing hopscotch" -s50 -W512 -H512 -C7.5 -mk_lms -S3498014304

# I wonder what it will look like if I bump up the steps and set facial enhancement to full strength?
dream> a cute child playing hopscotch -G1.0 -s100 -S -1
reusing previous seed 3498014304
[...]
outputs/img-samples/000040.3498014304.png: "a cute child playing hopscotch" -G1.0 -s100 -W512 -H512 -C7.5 -mk_lms -S3498014304
```

---

## **Simplified API**

For programmers who wish to incorporate stable-diffusion into other products, this repository
includes a simplified API for text to image generation, which lets you create images from a prompt
in just three lines of code:

```bash
from ldm.generate import Generate
g       = Generate()
outputs = g.txt2img("a unicorn in manhattan")
```

Outputs is a list of lists in the format [filename1,seed1],[filename2,seed2]...].

Please see ldm/generate.py for more information. A set of example scripts is coming RSN.

---

## **Preload Models**

In situations where you have limited internet connectivity or are blocked behind a firewall, you can
use the preload script to preload the required files for Stable Diffusion to run.

The preload script `scripts/preload_models.py` needs to be run once at least while connected to the
internet. In the following runs, it will load up the cached versions of the required files from the
`.cache` directory of the system.

```bash
(ldm) ~/stable-diffusion$ python3 ./scripts/preload_models.py
preloading bert tokenizer...
Downloading: 100%|██████████████████████████████████| 28.0/28.0 [00:00<00:00, 49.3kB/s]
Downloading: 100%|██████████████████████████████████| 226k/226k [00:00<00:00, 2.79MB/s]
Downloading: 100%|██████████████████████████████████| 455k/455k [00:00<00:00, 4.36MB/s]
Downloading: 100%|██████████████████████████████████| 570/570 [00:00<00:00, 477kB/s]
...success
preloading kornia requirements...
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /u/lstein/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth
100%|███████████████████████████████████████████████| 5.10M/5.10M [00:00<00:00, 101MB/s]
...success
```
