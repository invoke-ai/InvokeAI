{
    "add_embedding.linear_1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "add_embedding.linear_1.weight": {
        "shape": [
            1280,
            2816
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "add_embedding.linear_2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "add_embedding.linear_2.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "conv_in.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "conv_in.weight": {
        "shape": [
            320,
            4,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "conv_norm_out.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "conv_norm_out.weight": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "conv_out.bias": {
        "shape": [
            4
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "conv_out.weight": {
        "shape": [
            4,
            320,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.downsamplers.0.conv.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.downsamplers.0.conv.weight": {
        "shape": [
            320,
            320,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.0.conv1.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.0.conv1.weight": {
        "shape": [
            320,
            320,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.0.conv2.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.0.conv2.weight": {
        "shape": [
            320,
            320,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.0.norm1.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.0.norm1.weight": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.0.norm2.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.0.norm2.weight": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.0.time_emb_proj.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.0.time_emb_proj.weight": {
        "shape": [
            320,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.1.conv1.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.1.conv1.weight": {
        "shape": [
            320,
            320,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.1.conv2.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.1.conv2.weight": {
        "shape": [
            320,
            320,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.1.norm1.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.1.norm1.weight": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.1.norm2.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.1.norm2.weight": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.1.time_emb_proj.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.0.resnets.1.time_emb_proj.weight": {
        "shape": [
            320,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.norm.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.norm.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.proj_in.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.proj_in.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.proj_out.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.proj_out.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            5120,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            640,
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            5120,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            640,
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.norm3.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.0.transformer_blocks.1.norm3.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.norm.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.norm.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.proj_in.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.proj_in.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.proj_out.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.proj_out.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            5120,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            640,
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            5120,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            640,
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.norm3.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.attentions.1.transformer_blocks.1.norm3.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.downsamplers.0.conv.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.downsamplers.0.conv.weight": {
        "shape": [
            640,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.conv1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.conv1.weight": {
        "shape": [
            640,
            320,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.conv2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.conv2.weight": {
        "shape": [
            640,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.conv_shortcut.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.conv_shortcut.weight": {
        "shape": [
            640,
            320,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.norm1.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.norm1.weight": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.time_emb_proj.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.0.time_emb_proj.weight": {
        "shape": [
            640,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.1.conv1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.1.conv1.weight": {
        "shape": [
            640,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.1.conv2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.1.conv2.weight": {
        "shape": [
            640,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.1.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.1.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.1.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.1.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.1.time_emb_proj.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.1.resnets.1.time_emb_proj.weight": {
        "shape": [
            640,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.norm.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.norm.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.proj_in.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.proj_in.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.proj_out.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.proj_out.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.1.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.2.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.3.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.4.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.5.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.6.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.7.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.8.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.0.transformer_blocks.9.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.norm.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.norm.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.proj_in.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.proj_in.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.proj_out.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.proj_out.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.1.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.2.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.3.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.4.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.5.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.6.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.7.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.8.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.attentions.1.transformer_blocks.9.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.conv1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.conv1.weight": {
        "shape": [
            1280,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.conv2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.conv2.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.conv_shortcut.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.conv_shortcut.weight": {
        "shape": [
            1280,
            640,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.time_emb_proj.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.0.time_emb_proj.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.1.conv1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.1.conv1.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.1.conv2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.1.conv2.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.1.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.1.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.1.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.1.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.1.time_emb_proj.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "down_blocks.2.resnets.1.time_emb_proj.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.norm.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.norm.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.proj_in.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.proj_in.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.proj_out.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.proj_out.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.0.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.1.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.2.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.3.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.4.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.5.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.6.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.7.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.8.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.attentions.0.transformer_blocks.9.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.0.conv1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.0.conv1.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.0.conv2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.0.conv2.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.0.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.0.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.0.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.0.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.0.time_emb_proj.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.0.time_emb_proj.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.1.conv1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.1.conv1.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.1.conv2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.1.conv2.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.1.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.1.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.1.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.1.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.1.time_emb_proj.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "mid_block.resnets.1.time_emb_proj.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "time_embedding.linear_1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "time_embedding.linear_1.weight": {
        "shape": [
            1280,
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "time_embedding.linear_2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "time_embedding.linear_2.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.norm.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.norm.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.proj_in.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.proj_in.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.proj_out.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.proj_out.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.0.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.1.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.2.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.3.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.4.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.5.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.6.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.7.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.8.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.0.transformer_blocks.9.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.norm.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.norm.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.proj_in.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.proj_in.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.proj_out.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.proj_out.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.0.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.1.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.2.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.3.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.4.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.5.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.6.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.7.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.8.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.1.transformer_blocks.9.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.norm.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.norm.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.proj_in.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.proj_in.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.proj_out.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.proj_out.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.0.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.1.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.2.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.3.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.4.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.5.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.6.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.7.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.8.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_k.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_v.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_k.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_out.0.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_out.0.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_q.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_v.weight": {
        "shape": [
            1280,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.ff.net.0.proj.bias": {
        "shape": [
            10240
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.ff.net.0.proj.weight": {
        "shape": [
            10240,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.ff.net.2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.ff.net.2.weight": {
        "shape": [
            1280,
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.norm3.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.attentions.2.transformer_blocks.9.norm3.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.conv1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.conv1.weight": {
        "shape": [
            1280,
            2560,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.conv2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.conv2.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.conv_shortcut.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.conv_shortcut.weight": {
        "shape": [
            1280,
            2560,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.norm1.bias": {
        "shape": [
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.norm1.weight": {
        "shape": [
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.time_emb_proj.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.0.time_emb_proj.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.conv1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.conv1.weight": {
        "shape": [
            1280,
            2560,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.conv2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.conv2.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.conv_shortcut.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.conv_shortcut.weight": {
        "shape": [
            1280,
            2560,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.norm1.bias": {
        "shape": [
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.norm1.weight": {
        "shape": [
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.time_emb_proj.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.1.time_emb_proj.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.conv1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.conv1.weight": {
        "shape": [
            1280,
            1920,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.conv2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.conv2.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.conv_shortcut.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.conv_shortcut.weight": {
        "shape": [
            1280,
            1920,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.norm1.bias": {
        "shape": [
            1920
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.norm1.weight": {
        "shape": [
            1920
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.norm2.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.norm2.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.time_emb_proj.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.resnets.2.time_emb_proj.weight": {
        "shape": [
            1280,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.upsamplers.0.conv.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.0.upsamplers.0.conv.weight": {
        "shape": [
            1280,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.norm.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.norm.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.proj_in.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.proj_in.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.proj_out.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.proj_out.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            5120,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            640,
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            5120,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            640,
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.norm3.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.0.transformer_blocks.1.norm3.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.norm.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.norm.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.proj_in.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.proj_in.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.proj_out.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.proj_out.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            5120,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            640,
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            5120,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            640,
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.norm3.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.1.transformer_blocks.1.norm3.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.norm.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.norm.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.proj_in.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.proj_in.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.proj_out.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.proj_out.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias": {
        "shape": [
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight": {
        "shape": [
            5120,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight": {
        "shape": [
            640,
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_k.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_v.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_k.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_out.0.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_out.0.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_q.weight": {
        "shape": [
            640,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_v.weight": {
        "shape": [
            640,
            2048
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.ff.net.0.proj.bias": {
        "shape": [
            5120
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.ff.net.0.proj.weight": {
        "shape": [
            5120,
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.ff.net.2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.ff.net.2.weight": {
        "shape": [
            640,
            2560
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.norm3.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.attentions.2.transformer_blocks.1.norm3.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.conv1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.conv1.weight": {
        "shape": [
            640,
            1920,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.conv2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.conv2.weight": {
        "shape": [
            640,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.conv_shortcut.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.conv_shortcut.weight": {
        "shape": [
            640,
            1920,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.norm1.bias": {
        "shape": [
            1920
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.norm1.weight": {
        "shape": [
            1920
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.time_emb_proj.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.0.time_emb_proj.weight": {
        "shape": [
            640,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.conv1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.conv1.weight": {
        "shape": [
            640,
            1280,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.conv2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.conv2.weight": {
        "shape": [
            640,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.conv_shortcut.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.conv_shortcut.weight": {
        "shape": [
            640,
            1280,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.norm1.bias": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.norm1.weight": {
        "shape": [
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.time_emb_proj.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.1.time_emb_proj.weight": {
        "shape": [
            640,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.conv1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.conv1.weight": {
        "shape": [
            640,
            960,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.conv2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.conv2.weight": {
        "shape": [
            640,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.conv_shortcut.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.conv_shortcut.weight": {
        "shape": [
            640,
            960,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.norm1.bias": {
        "shape": [
            960
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.norm1.weight": {
        "shape": [
            960
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.norm2.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.norm2.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.time_emb_proj.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.resnets.2.time_emb_proj.weight": {
        "shape": [
            640,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.upsamplers.0.conv.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.1.upsamplers.0.conv.weight": {
        "shape": [
            640,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.conv1.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.conv1.weight": {
        "shape": [
            320,
            960,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.conv2.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.conv2.weight": {
        "shape": [
            320,
            320,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.conv_shortcut.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.conv_shortcut.weight": {
        "shape": [
            320,
            960,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.norm1.bias": {
        "shape": [
            960
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.norm1.weight": {
        "shape": [
            960
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.norm2.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.norm2.weight": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.time_emb_proj.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.0.time_emb_proj.weight": {
        "shape": [
            320,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.conv1.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.conv1.weight": {
        "shape": [
            320,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.conv2.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.conv2.weight": {
        "shape": [
            320,
            320,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.conv_shortcut.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.conv_shortcut.weight": {
        "shape": [
            320,
            640,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.norm2.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.norm2.weight": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.time_emb_proj.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.1.time_emb_proj.weight": {
        "shape": [
            320,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.conv1.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.conv1.weight": {
        "shape": [
            320,
            640,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.conv2.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.conv2.weight": {
        "shape": [
            320,
            320,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.conv_shortcut.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.conv_shortcut.weight": {
        "shape": [
            320,
            640,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.norm1.bias": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.norm1.weight": {
        "shape": [
            640
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.norm2.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.norm2.weight": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.time_emb_proj.bias": {
        "shape": [
            320
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "up_blocks.2.resnets.2.time_emb_proj.weight": {
        "shape": [
            320,
            1280
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    }
}